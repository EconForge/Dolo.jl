name: RBC

symbols:

   markov_states: [z]
   states:  [k]
   controls: [i, n]
   auxiliaries: [y, c, rk, w]
   rewards: [u]

   parameters: [beta, sigma, eta, chi, delta, alpha, rho, zbar, sig_z, kmax]

equations:


   transition:
      - k = (1-delta)*k(-1) + i(-1)

   arbitrage:
      - 1 - beta*(c/c(1))^(sigma)*(1-delta+rk(1))     | 0.0 <= i <= k*0.2
    #   - 1 - beta*(1-delta+rk(1))     | 0.0 <= i <= k*0.2
      - chi*n^eta*c^sigma - w                         | 0.1 <= n <= 2.0

   auxiliary:
      - y = exp(z)*k^alpha*n^(1-alpha)
      - c = y - i
      - rk = alpha*y/k
      - w = (1-alpha)*y/n

   felicity:
       - u =  c^(1-sigma)/(1-sigma) - chi*n^(1+eta)/(1+eta)

calibration:

    #parameters:

    beta : 0.99
    phi: 1
    chi : w/c^sigma/n^eta
    delta : 0.025
    alpha : 0.33
    rho : 0.8
    sigma: 4.0
    eta: 2.0
    zbar: 1.0
    sig_z: 0.001**2
    kmax: 2.0

    # constant initial values:
    z: 0
    rk: 1/beta-1+delta
    w: (1-alpha)*exp(z)*(k/n)^(alpha)
    n: 0.33
    k: n/(rk/alpha)^(1/(1-alpha))
    i: delta*k
    c: y - i
    y: exp(z)*k^alpha*n^(1-alpha)
    # u: c^(1-sigma)/(1-sigma) + chi*n^(eta-1)/(eta-1)
    u: c^(1-sigma)/(1-sigma)  - chi*n^(1+eta)/(1+eta)


options:

    approximation_space:

        a: [k*0.5]
        b: [k*1.5]
        orders: [30]
    discrete_transition:


        MarkovChain:

            - [[ -0.01],
                [ 0.01]]
            - [[ 0.5, 0.5],
               [ 0.5, 0.5]]


        # MarkovChain:
        #
        #     - [[ 0.99 ],  # bad state
        #     [ 1. ]]          # good state
        #
        #     - [[ 0.5, 1-0.5 ],   # probabilities   [p(L|L), p(H|L)]
        #     [ 0.5, 0.5 ]]     # probabilities   [p(L|H), p(H|H)]
